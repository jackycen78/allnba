{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nba.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucct7sfUqUHA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import re"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9j-X8cdl16n"
      },
      "source": [
        "def player_stats_by_year():\n",
        "\n",
        "  all_players = []\n",
        "\n",
        "  current_year = 1989\n",
        "  end_year = 2020\n",
        "  all_nba_team = all_nba()\n",
        "\n",
        "  \n",
        "  for year in range(current_year, end_year +1):\n",
        "    # Load the yearly player stats\n",
        "    url = \"https://www.basketball-reference.com/leagues/NBA_{}_per_game.html\".format(year)\n",
        "    html = urlopen(url)\n",
        "    soup = BeautifulSoup(html)\n",
        "    # Find the statistics/column names\n",
        "    columns = []\n",
        "    for col in soup.find('tr').findAll('th'):\n",
        "      columns.append(col.getText())\n",
        "    columns.append(\"YEAR\")\n",
        "    columns.append(\"ALL-NBA\")\n",
        "    columns = columns [1:]\n",
        "\n",
        "\n",
        "    # Find the player data for each column\n",
        "    players = soup.findAll('tr')[1:]\n",
        "    for player in range(len(players)):\n",
        "      stats = []\n",
        "      for stat in players[player].findAll('td'):\n",
        "        stats.append(stat.getText())\n",
        "      stats.append(year)\n",
        "      # Players that are inducted in the hall of fame have an \n",
        "      # asterisks beside their names. We need to remove it to\n",
        "      # properly match with the All NBA data.\n",
        "      if str(stats[0])[-1] == \"*\":\n",
        "        stats[0] = stats[0][:-1]\n",
        "      # If player is in an All NBA team assign them a 1, \n",
        "      # otherwise a 0.\n",
        "      if year in all_nba_team and stats[0] in all_nba_team[year]:\n",
        "        stats.append(1)\n",
        "      else:\n",
        "        stats.append(0)\n",
        "      all_players.append(stats)\n",
        "\n",
        "\n",
        "  stats = pd.DataFrame(all_players, columns = columns)\n",
        "  return stats"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juv5-0ILZniT"
      },
      "source": [
        "def all_nba():\n",
        "  \n",
        "  url = \"https://www.basketball-reference.com/awards/all_league.html\"\n",
        "  html = urlopen(url)\n",
        "  soup = BeautifulSoup(html)\n",
        "\n",
        "  all_nba_by_year = {}\n",
        "  start_year = 1988\n",
        "  end_year = 2020\n",
        "  counter = 0\n",
        "  \n",
        "  # Find every player \n",
        "  for row in soup.find_all('tr'):\n",
        "    players = row.find_all('a')[2:]\n",
        "    for player in players:\n",
        "      player = player.getText()\n",
        "      if counter == 15:\n",
        "        end_year -= 1\n",
        "        counter = 0\n",
        "      if end_year >= start_year:\n",
        "        if end_year in all_nba_by_year:\n",
        "          all_nba_by_year[end_year].append(player)\n",
        "        else:\n",
        "          all_nba_by_year[end_year] = [player]\n",
        "      counter += 1\n",
        "\n",
        "\n",
        "  return  all_nba_by_year"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt1VqcgWhzo2"
      },
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "\n",
        "Lets look at a few years of player data, to see what we are working with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWU_Cg2qhyyE"
      },
      "source": [
        "players_df = player_stats_by_year()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eePkqFBe3r35"
      },
      "source": [
        "players_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ppfy7zEXxnEk"
      },
      "source": [
        "print(\"The shape of the dataset is :\", players_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ui3cSi4atrv"
      },
      "source": [
        "players_df.groupby(['YEAR']).agg(['sum'])['ALL-NBA']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfVZZqUlbXIz"
      },
      "source": [
        "players_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTAsByTA50J3"
      },
      "source": [
        "### Removing null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSE3SP4M6dFS"
      },
      "source": [
        "players_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmePe_QB6Opp"
      },
      "source": [
        "players_df.dropna(axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K80u7Ja977FL"
      },
      "source": [
        "### Removing duplicate values\n",
        "\n",
        "Let's look at an example of a player who has been traded mid-season. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnLgpMz_77O2"
      },
      "source": [
        "players_df[(players_df[\"Player\"] == 'Robert Covington') & (players_df[\"YEAR\"] == 2019)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSdkb70Oshvd"
      },
      "source": [
        "players_df.drop_duplicates(subset=['Player', 'YEAR'], keep='first', inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSf1SM-lso6l"
      },
      "source": [
        "If we run the query on that specific player again, we will only see one row."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pcbJAggt0L4"
      },
      "source": [
        "players_df[(players_df[\"Player\"] == 'Robert Covington') & (players_df[\"YEAR\"] == 2019)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBqNXNjbt9_i"
      },
      "source": [
        "### Changing player positions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBuCwu8Dt8n4"
      },
      "source": [
        "players_df[\"Pos\"].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KonxFdSk91Dz"
      },
      "source": [
        "Notice that player can be listed as having played in multiple positions. This can be attributed to the fact players switching teams mid-season may have a new role on the new team. The data lists the position played most first, so I will be using that as the main position. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcPCyiI5cROw"
      },
      "source": [
        "def main_position(position):\n",
        "\n",
        "  if position.startswith('C'):\n",
        "    return 'C'\n",
        "  elif position == 'G':\n",
        "    return 'PG'\n",
        "  else:\n",
        "    return position[:2]\n",
        "\n",
        "players_df['Pos'] = players_df['Pos'].apply(main_position)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wopZTqgDF4KM"
      },
      "source": [
        "We can see if this worked by checking the unique values again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hkeZaXnyLF6"
      },
      "source": [
        "players_df[\"Pos\"].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w5sDmitGGU_"
      },
      "source": [
        "If we were to one hot encode the positions, we would come up with an error. This is because we already have an existing column PF(personal fouls) with the position PF(power foward). So we can simply fix this by changing the personal fouls column name to \"FOULS\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ip98GFoGFRQ"
      },
      "source": [
        "players_df.rename(columns={\"PF\": \"FOULS\"}, inplace=True )\n",
        "one_hot = pd.get_dummies(players_df['Pos'])\n",
        "players_df.drop('Pos', axis = 1, inplace=True)\n",
        "players_df = players_df.join(one_hot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUZtMoP5tCBQ"
      },
      "source": [
        "players_df.drop(['Tm', 'Player', '3P%'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_Dv8hGQhkvb"
      },
      "source": [
        "players_df = players_df.apply(pd.to_numeric)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVkSUHj-NgDG"
      },
      "source": [
        "players_df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa8yhvR4L6zC"
      },
      "source": [
        "players_df = players_df[(players_df['G'] > 15) & (players_df['MP'] > 15)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vT407-ffK8t"
      },
      "source": [
        "players_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWxcSrLEKIGw"
      },
      "source": [
        "## Exploratory Data Analysis\n",
        "\n",
        "First lets take a look at each individual statistic's distribution.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p803S57OP2CC"
      },
      "source": [
        "width = 5\n",
        "height = 6\n",
        "\n",
        "fig, ax = plt.subplots(height, width)\n",
        "fig.subplots_adjust(bottom = 0, top = height - 1, \n",
        "                    left = 0, right = width - 1 )\n",
        "\n",
        "columns = players_df.columns[1:30]\n",
        "\n",
        "n = 0\n",
        "m = 0\n",
        "for col in columns:\n",
        "  sns.histplot(players_df[col], kde=True, element=\"step\", ax = ax[n][m])\n",
        "  if m == width - 1:\n",
        "    m = 0\n",
        "    n += 1\n",
        "  else:\n",
        "    m += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEfJmQbCOdbm"
      },
      "source": [
        "Next, we can compare the boxplots of the statistics between all NBA and non all NBA players.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksmxlnLiWapa"
      },
      "source": [
        "width = 3\n",
        "height = 7\n",
        "\n",
        "fig, ax = plt.subplots(height, width)\n",
        "fig.subplots_adjust(bottom = 0, top = height - 1, \n",
        "                    left = 0, right = width - 1 )\n",
        "\n",
        "columns = players_df.columns[2:23]\n",
        "\n",
        "n = 0\n",
        "m = 0\n",
        "for col in columns:\n",
        "  sns.boxplot(x=\"ALL-NBA\", y = col, data=players_df, ax = ax[n][m])\n",
        "  if m == width - 1:\n",
        "    m = 0\n",
        "    n += 1\n",
        "  else:\n",
        "    m += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVmgERy1PTkz"
      },
      "source": [
        "Finally, we can check the correlation of each player statistic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwdF04foaapW"
      },
      "source": [
        "corr = players_df.corr()\n",
        "fig, ax = plt.subplots(figsize=(20, 20))\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTyutOCw72xO"
      },
      "source": [
        "## Creating train/test data\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjcmlQXTOKX1"
      },
      "source": [
        "predictors = players_df.drop('ALL-NBA', axis=1, inplace=False)\n",
        "outcome = players_df['ALL-NBA']\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(predictors, outcome, test_size = 0.3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KCGMu47fYkP"
      },
      "source": [
        "print(\"The shape of X train is :\", X_train.shape)\n",
        "print(\"The shape of X test is :\", X_test.shape)\n",
        "print(\"The shape of Y train is :\", Y_train.shape)\n",
        "print(\"The shape of Y test is :\", Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pzk3gfJJQEan"
      },
      "source": [
        "## Univariate logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gM_UiXLQfp-N"
      },
      "source": [
        "def logistic_regression(col, weight=None):\n",
        "\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(predictors, outcome, test_size = 0.3)\n",
        "\n",
        "  if type(col) == str:\n",
        "    X_test = X_test[col].values.reshape(-1, 1)\n",
        "    X_train = X_train[col].values.reshape(-1, 1)\n",
        "  else:\n",
        "    X_test = X_test[col]\n",
        "    X_train = X_train[col]\n",
        "\n",
        "  model = LogisticRegression(class_weight = weight)\n",
        "  model.fit(X_train, Y_train)\n",
        "\n",
        "  predict = model.predict(X_test)\n",
        "  accuracy = model.score(X_test, Y_test)\n",
        "  roc = roc_auc_score(Y_test, predict)\n",
        "\n",
        "  print(\"Accuracy: {}\".format(accuracy))\n",
        "  print(\"AUC-ROC: {}\".format(roc))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqcPSY0jba3h"
      },
      "source": [
        "logistic_regression('PTS', weight = 'balanced')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwzUDBwv8daM"
      },
      "source": [
        "logistic_regression('STL', weight = 'balanced')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DibZ42gI8dhS"
      },
      "source": [
        "logistic_regression('FG%', weight = 'balanced')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OoKYkrN84Os"
      },
      "source": [
        "Looking at the scores of these univarate logistic regression models, it seems like it's prediction is good. However, the evaluation metric that score() uses is the accuracy. This is the percentage of outcomes that the model has predicted correctly. However, since there are such a low number of all-nba players (~5%), the model can predict the players to be all false (not all nba team) and still achieve an accuracy of ~95%.\n",
        "\n",
        "Alternatively we can look at the confusion matrix below, where the,\n",
        "  - top left value: actual value is false and predicted value is false (True negative)\n",
        "  - top right value: actual value is false and predicted value is true (False positive)\n",
        "  - bottom left value: actual value is true and predicted value is false (False positive)\n",
        "  - bottom right value: actual value is true and predicted value is true (False positive)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFyr6RqFLR6Z"
      },
      "source": [
        "This shows that the model is good at correctly predicting non-all nba players, but struggles at correctly identifying the other possibilities. To fix this class imbalance, one way would be to add weights to the model. This penalizes wrong predictions of the \"all nba team\" significantly more than wrong predictions of non \"all nba team\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRCn-IwnFeWb"
      },
      "source": [
        "def plot_logistic(model1, col):\n",
        "\n",
        "  low = np.min(players_df[col])\n",
        "  high = np.max(players_df[col])\n",
        "\n",
        "  nonallnbaavg = np.mean(players_df[players_df['ALL-NBA'] == 0][col])\n",
        "  allnbaavg = np.mean(players_df[players_df['ALL-NBA'] == 1][col])\n",
        "\n",
        "  x = np.linspace(low, high, 200)\n",
        "  x_prob = np.reshape(x, (200, 1))\n",
        "  y_prob = model1.predict_proba(x_prob)[:,1]\n",
        "\n",
        "  plt.plot(x_prob, y_prob, color = 'black')\n",
        "  plt.vlines(nonallnbaavg, ymin = 0, ymax = 1, color='blue', linestyles='dashed', label= 'non-All NBA')\n",
        "  plt.vlines(allnbaavg, ymin = 0, ymax = 1, color='red', linestyles='dashed', label='All NBA')\n",
        "  plt.title('Probability of making All NBA team, given {}'.format(col))\n",
        "  plt.xlabel(col)\n",
        "  plt.legend(title = 'Mean', loc='lower right' )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc8ZCdNtFqPK"
      },
      "source": [
        "plot_logistic(logistic_regression('PTS', weight = 'balanced'), 'PTS')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA8C3PBM1rWa"
      },
      "source": [
        "plot_logistic(logistic_regression('STL', weight = 'balanced'), 'STL')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwV69sYr1rvR"
      },
      "source": [
        "plot_logistic(logistic_regression('FG%', weight = 'balanced'), 'FG%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77Il7lJtQn5l"
      },
      "source": [
        "## Multivariate logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sSxkKklNW9s"
      },
      "source": [
        "def logistic_regression2(col, weight=None, scale=False):\n",
        "\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(predictors, outcome, test_size = 0.3)\n",
        "\n",
        "  if type(col) == str:\n",
        "    X_test = X_test[col].values.reshape(-1, 1)\n",
        "    X_train = X_train[col].values.reshape(-1, 1)\n",
        "  else:\n",
        "    X_test = X_test[col]\n",
        "    X_train = X_train[col]\n",
        "    if scale:\n",
        "      scaler = MinMaxScaler()\n",
        "      X_test = scaler.fit_transform(X_test)\n",
        "      X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "  model = LogisticRegression(class_weight = weight, max_iter=5000)\n",
        "  model.fit(X_train, Y_train)\n",
        "\n",
        "  predict = model.predict(X_test)\n",
        "  accuracy = accuracy_score(Y_test, predict)\n",
        "  roc = roc_auc_score(Y_test, predict)\n",
        "\n",
        "\n",
        "  print(\"Accuracy: {}\".format(accuracy))\n",
        "  print(\"AUC-ROC: {}\".format(roc))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4tKFlrcUKQG"
      },
      "source": [
        "col = ['GS', 'MP', 'FG', 'FGA', '2P', '2PA', 'FT', 'FTA', 'DRB', 'TRB', 'AST', 'STL', 'PTS', 'TOV']\n",
        "model = logistic_regression2(col, weight='balanced')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ly5XjA7hvUsp"
      },
      "source": [
        "col2 = ['GS', 'MP', 'FGA', '2PA', 'FTA', 'TRB', 'AST', 'STL', 'PTS', 'TOV']\n",
        "model2 = logistic_regression2(col2, weight='balanced')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmO91isAQrvS"
      },
      "source": [
        "## Random forests"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aA9IwDtQ2yi"
      },
      "source": [
        "rf = RandomForestRegressor(random_state = 1)\n",
        "rf.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaxvxW9NfLBb"
      },
      "source": [
        "predict = rf.predict(X_test)\n",
        "acc = 1 - mean_squared_error(Y_test, predict)\n",
        "roc = roc_auc_score(Y_test, predict)\n",
        "\n",
        "print(\"MSE: {}\".format(acc))\n",
        "print(\"AUC-ROC: {}\".format(roc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3rmvAx8SRBt"
      },
      "source": [
        "Create grid search to find the best possible combinations of hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-VJUBdSKdR3"
      },
      "source": [
        "n_estimators = [100, 500, 1000]\n",
        "max_features = ['auto', 'log']\n",
        "max_depth = [10, 20, 30]\n",
        "min_samples_split = [10, 50, 100]\n",
        "min_samples_leaf = [5, 10, 50]\n",
        "\n",
        "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  \n",
        "              min_samples_split = min_samples_split, \n",
        "             min_samples_leaf = min_samples_leaf,\n",
        "              max_features = max_features)\n",
        "\n",
        "gridF = GridSearchCV(rf, hyperF, cv = 3, verbose = 1, \n",
        "                      n_jobs = -1)\n",
        "bestF = gridF.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_wAPvIvNsfm"
      },
      "source": [
        "rf = RandomForestRegressor(n_estimators = 1000, max_features=20, min_samples_leaf=1, min_samples_split=2, random_state=2)\n",
        "rf.fit(X_train, Y_train)\n",
        "\n",
        "\n",
        "predict = rf.predict(X_test)\n",
        "acc = 1 - mean_squared_error(Y_test, predict)\n",
        "roc = roc_auc_score(Y_test, predict)\n",
        "\n",
        "print(\"MSE: {}\".format(acc))\n",
        "print(\"AUC-ROC: {}\".format(roc))\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}